# YDB configuration options and their values
# are described in documentaion https://ydb.tech/en/docs/deploy/configuration/config

# erasure is the parameter that
# describes the fault tolerance mode of the
# cluster. See docs for more details https://ydb.tech/en/docs/deploy/configuration/config#domains-blob
erasure: mirror-3-dc
host_configs: # the list of available host configurations in the cluster.
- host_config_id: 1
  drive:
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_01    # path of the first disk in the host configration.                                       # kind of the disk: available kinds are SSD, NVME, HDD
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_02
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_03

hosts:
- host: ydb-node-zone-a.local       # storage node DNS name
  host_config_id: 1                 # numeric host configuration template identifier
  location:                         # this parameter describes where host is located.
    data_center: 'zone-a'           # string representing the datacenter / availability zone where the host is located
- host: ydb-node-zone-b.local
  host_config_id: 1
  location:
    data_center: 'zone-b'
- host: ydb-node-zone-c.local
  host_config_id: 1
  location:
    data_center: 'zone-c'
domains_config:
  # There can be only one root domain in a cluster. Domain name prefixes all scheme objects names, e.g. full name of a table table1 in database db1.
  # in a cluster with domains_config.domain.name parameter set to Root would be equal to /Root/db1/table1
  domain:
  - name: Root
    storage_pool_types:
    - pool_config:
        box_id: 1
        geometry:
          realm_level_begin: 10
          realm_level_end: 20
          domain_level_begin: 10
          domain_level_end: 256
  state_storage:
  - ring:
      node: [1, 2, 3]
      nto_select: 3
    ssid: 1
blob_storage_config:         # configuration of static blobstorage group.
                             # YDB uses this group to store system tablets' data, like SchemeShard
  service_set:
    groups:
    - rings:          # in mirror-3-dc must have exactly 3 rings or availability zones
      - fail_domains:  # first record: fail domains of the static group describe where each vdisk of the static group should be located.
        - vdisk_locations:
          - node_id: ydb-node-zone-a.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_01
        - vdisk_locations:
          - node_id: ydb-node-zone-a.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_02
        - vdisk_locations:
          - node_id: ydb-node-zone-a.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_03
      - fail_domains: # second ring: fail domains of the static group describe where each vdisk of the static group should be located.
        - vdisk_locations:
          - node_id: ydb-node-zone-b.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_01
        - vdisk_locations:
          - node_id: ydb-node-zone-b.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_02
        - vdisk_locations:
          - node_id: ydb-node-zone-b.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_03
      - fail_domains: # third ring: fail domains of the static group describe where each vdisk of the static group should be located.
        - vdisk_locations:
          - node_id: ydb-node-zone-c.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_01
        - vdisk_locations:
          - node_id: ydb-node-zone-c.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_02
        - vdisk_locations:
          - node_id: ydb-node-zone-c.local
            path: /dev/disk/by-partlabel/ydb_disk_ssd_03
tls:
    cert: "/opt/ydb/certs/node.crt"
    key: "/opt/ydb/certs/node.key"
    ca: "/opt/ydb/certs/ca.crt"
